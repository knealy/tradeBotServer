# PostgreSQL Setup Guide for Trading Bot

This guide explains how to set up PostgreSQL for persistent caching and state management.

## ðŸš€ Quick Setup on Railway

Railway provides **FREE PostgreSQL** with your deployment!

### 1. Add PostgreSQL to Your Railway Project

```bash
# In Railway dashboard:
1. Go to your project
2. Click "+ New" â†’ "Database" â†’ "Add PostgreSQL"
3. Railway will automatically provision a PostgreSQL instance
4. DATABASE_URL will be automatically added to your environment
```

That's it! The bot will automatically detect and use PostgreSQL.

### 2. Verify Connection

Check your bot logs for:
```
âœ… PostgreSQL database initialized
```

If you see this, you're all set!

### 3. Optional: Manual Connection

If you need to connect manually, Railway provides these variables:
```bash
DATABASE_URL=postgresql://user:password@host:port/database

# Or individually:
POSTGRES_HOST=containers-us-west-123.railway.app
POSTGRES_PORT=5432
POSTGRES_DB=railway
POSTGRES_USER=postgres
POSTGRES_PASSWORD=xxxxx
```

---

## ðŸ”§ Local Development Setup

For testing locally, you can use Docker:

### Option A: Docker Compose (Recommended)

Create `docker-compose.yml`:
```yaml
version: '3.8'
services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_DB: trading_bot
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

volumes:
  postgres_data:
```

Start PostgreSQL:
```bash
docker-compose up -d
```

Add to `.env`:
```bash
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/trading_bot
```

### Option B: Direct Docker

```bash
docker run --name trading-postgres \
  -e POSTGRES_DB=trading_bot \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -p 5432:5432 \
  -d postgres:15
```

---

## ðŸ“Š What Gets Cached

### 1. Historical Market Data
- **Bars/Candles** for all symbols and timeframes
- **Survives restarts** - No need to re-fetch on bot restart
- **Smart caching** - Only fetches new data after market close

**Expected Performance:**
- Without cache: ~109ms per historical data fetch
- With cache: ~5ms per historical data fetch
- **95% faster on cached queries!**

### 2. Account State
- Current balance and daily P&L
- Daily Loss Limit (DLL) tracking
- Trade counters and statistics
- Persists across restarts

### 3. Strategy Performance
- Win rate, profit factor, Sharpe ratio
- Best/worst trades
- Historical performance tracking
- Enables performance analysis over time

### 4. API Performance Metrics
- Response times by endpoint
- Error rates
- Slow call tracking
- Historical performance trends

---

## ðŸ› ï¸ Database Management

### View Database Stats

Use the `metrics` command in the bot:
```bash
> metrics
```

Shows:
- Total cached bars
- Cache hit rates
- API performance
- System metrics

### Manual Database Access

Connect directly to inspect data:
```bash
# Using psql
psql $DATABASE_URL

# View tables
\dt

# Check cached bars
SELECT symbol, timeframe, COUNT(*) 
FROM historical_bars 
GROUP BY symbol, timeframe;

# View cache coverage
SELECT 
  symbol,
  timeframe,
  MIN(timestamp) as oldest,
  MAX(timestamp) as newest,
  COUNT(*) as bars
FROM historical_bars
GROUP BY symbol, timeframe;
```

### Cleanup Old Data

The bot automatically cleans up old data:
- Historical bars: Keeps 30 days
- API metrics: Keeps 7 days
- Account/strategy data: Kept indefinitely

Manual cleanup (if needed):
```sql
-- Delete bars older than 30 days
DELETE FROM historical_bars 
WHERE created_at < NOW() - INTERVAL '30 days';

-- Delete old API metrics
DELETE FROM api_metrics 
WHERE timestamp < NOW() - INTERVAL '7 days';
```

---

## ðŸ” Troubleshooting

### Error: "PostgreSQL unavailable (will use memory cache only)"

**Cause:** Database connection failed  
**Impact:** Bot will still work, but uses memory cache (lost on restart)

**Solutions:**
1. **Railway**: Make sure PostgreSQL service is running
2. **Local**: Start PostgreSQL Docker container
3. **Check logs** for specific error message

### Error: "relation 'historical_bars' does not exist"

**Cause:** Database schema not initialized  
**Fix:** Restart the bot - schema creates automatically on first run

### Slow Performance

**Check:**
```bash
# View slow queries
SELECT endpoint, AVG(duration_ms) 
FROM api_metrics 
WHERE timestamp > NOW() - INTERVAL '1 hour'
GROUP BY endpoint 
ORDER BY AVG(duration_ms) DESC;
```

### Database Size Growing Too Large

**Monitor:**
```sql
-- Check database size
SELECT pg_size_pretty(pg_database_size('railway'));

-- Check table sizes
SELECT 
  tablename,
  pg_size_pretty(pg_total_relation_size(tablename::text))
FROM pg_tables 
WHERE schemaname = 'public';
```

**Solution:** Reduce retention period or delete old data manually

---

## ðŸ“ˆ Performance Benefits

### Before PostgreSQL Cache:
```
Bot Startup: ~500ms
Historical Data Query: ~109ms (API call every time)
Account State: Lost on restart
Metrics: In-memory only
```

### After PostgreSQL Cache:
```
Bot Startup: ~250ms (50% faster!)
Historical Data Query: ~5ms (95% faster!)
Account State: Persisted across restarts
Metrics: Tracked historically
```

### Cache Hit Rates

Expected performance after first run:
- **Historical data**: 85%+ hit rate
- **Account lookups**: 95%+ hit rate
- **Overall API reduction**: 70%+ fewer calls

---

## ðŸŽ¯ Production Best Practices

### 1. Backups
Railway automatically backs up your database daily. For manual backups:
```bash
pg_dump $DATABASE_URL > backup.sql
```

### 2. Monitoring
Check cache performance regularly:
```bash
> metrics
```

Look for:
- High cache hit rates (>80%)
- Low API error rates (<1%)
- Fast response times (<100ms avg)

### 3. Indexing
The bot creates indexes automatically. If you add custom queries, ensure proper indexing:
```sql
CREATE INDEX idx_custom ON historical_bars(symbol, timestamp DESC);
```

### 4. Connection Pooling
The bot uses connection pooling (2-10 connections) for efficiency. No configuration needed!

---

## ðŸš€ Next Steps

With PostgreSQL set up, you now have:

âœ… **Persistent caching** - No data loss on restart  
âœ… **95% faster queries** - After first fetch  
âœ… **Historical tracking** - Performance metrics over time  
âœ… **Production ready** - Built for scale  

Ready to build your dashboard!

---

## Need Help?

- **Railway Issues**: Check Railway status page
- **Connection Problems**: Verify `DATABASE_URL` in environment
- **Performance**: Run `metrics` command to analyze
- **Custom Queries**: See PostgreSQL documentation

**Tip**: The bot works WITHOUT PostgreSQL (using memory cache), so database issues won't stop trading!

